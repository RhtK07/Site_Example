
  <head>
    <title>Requests for Research</title>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1">



<link rel="apple-touch-icon" sizes="57x57" href="../assets/img/apple-touch-icon-57x57.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="60x60" href="../assets/img/apple-touch-icon-60x60.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="72x72" href="../assets/img/apple-touch-icon-72x72.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="76x76" href="../assets/img/apple-touch-icon-76x76.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="114x114" href="../assets/img/apple-touch-icon-114x114.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="120x120" href="../assets/img/apple-touch-icon-120x120.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="144x144" href="../assets/img/apple-touch-icon-144x144.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="152x152" href="../assets/img/apple-touch-icon-152x152.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="180x180" href="../assets/img/apple-touch-icon-180x180.png?v=wAAv6Wqe6l">
<link rel="icon" type="image/png" href="../assets/img/favicon-32x32.png?v=wAAv6Wqe6l" sizes="32x32">
<link rel="icon" type="image/png" href="../assets/img/favicon-194x194.png?v=wAAv6Wqe6l" sizes="194x194">
<link rel="icon" type="image/png" href="../assets/img/favicon-96x96.png?v=wAAv6Wqe6l" sizes="96x96">
<link rel="icon" type="image/png" href="../assets/img/android-chrome-192x192.png?v=wAAv6Wqe6l" sizes="192x192">
<link rel="icon" type="image/png" href="../assets/img/favicon-16x16.png?v=wAAv6Wqe6l" sizes="16x16">
<link rel="manifest" href="../assets/img/manifest.json?v=wAAv6Wqe6l">
<link rel="shortcut icon" href="../assets/img/favicon.ico?v=wAAv6Wqe6l">
<meta name="msapplication-TileColor" content="#e74c3c">
<meta name="msapplication-TileImage" content="/assets/img/mstile-144x144.png?v=wAAv6Wqe6l">
<meta name="msapplication-config" content="/assets/img/browserconfig.xml?v=wAAv6Wqe6l">
<meta name="theme-color" content="#e74c3c">
    <link rel="stylesheet" type="text/css" href="../assets/css/uno-zen.css?v=eab98792e1">
    <link rel="canonical" href="http://ruder.io/requests-for-research/">
    <meta name="referrer" content="origin">
    
    <meta property="og:site_name" content="Sebastian Ruder">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Requests for Research">
    <meta property="og:description" content="Table of contents: Task-independent data augmentation for NLP Few-shot learning for NLP Transfer learning for NLP Multi-task learning Cross-lingual learning Task-independent architecture improvements It can be hard to find compelling topics to work on and know what questions are interesting...">
    <meta property="og:url" content="u=http://ruder.io/requests-for-research/">
    <meta property="article:published_time" content="2018-03-04T15:00:00.000Z">
    <meta property="article:modified_time" content="2018-03-06T16:20:27.243Z">
    <meta property="article:tag" content="deep learning">
    <meta property="article:tag" content="nlp">
    <meta property="article:tag" content="transfer learning">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Requests for Research">
    <meta name="twitter:description" content="Table of contents: Task-independent data augmentation for NLP Few-shot learning for NLP Transfer learning for NLP Multi-task learning Cross-lingual learning Task-independent architecture improvements It can be hard to find compelling topics to work on and know what questions are interesting...">
    <meta name="twitter:url" content="u=http://ruder.io/requests-for-research/">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Sebastian Ruder",
    "author": {
        "@type": "Person",
        "name": "Sebastian Ruder",
        "url": "u=http://ruder.io/author/sebastian",
        "sameAs": null,
        "description": null
    },
    "headline": "Requests for Research",
    "url": "u=http://ruder.io/requests-for-research/",
    "datePublished": "2018-03-04T15:00:00.000Z",
    "dateModified": "2018-03-06T16:20:27.243Z",
    "keywords": "deep learning, nlp, transfer learning",
    "description": "Table of contents: Task-independent data augmentation for NLP Few-shot learning for NLP Transfer learning for NLP Multi-task learning Cross-lingual learning Task-independent architecture improvements It can be hard to find compelling topics to work on and know what questions are interesting..."
}
    </script>

    <meta name="generator" content="Ghost 0.7">
    <link rel="alternate" type="application/rss+xml" title="Sebastian Ruder" href="http://ruder.io/rss/">
    <script>
var open_button = '.nav-blog > a'
</script>
<script>
var profile_title = 'Sebastian Ruder';
</script>
<script>
var disqus_shortname = 'sebastianruder';
</script>
<script>
var profile_resume ='NLP PhD student';
</script>
<script>
var ga_id = 'UA-60512592-1';
</script>
  </head>
  <body class="post-template tag-deep-learning tag-nlp tag-transfer-learning">
    <header id="menu-button" class="expanded">
      <a><i class="icon icon-list"></i></a>
    </header>
    <aside class="cover" style="background: url(../content/images/2017/05/imageedit_8_8459453433.jpg) center/cover no-repeat fixed">
  <div class="cover container">
    <div class="profile">
      <a id="avatar-link" title="link to homepage for Sebastian Ruder" href="http://ruder.io/#open">
        <img src="../content/images/2015/12/Seb_LinkedIn_Profile-.png" alt="Sebastian Ruder avatar" class="profile avatar rounded hvr-buzz-out">
        <h1 id="profile-title">Sebastian Ruder</h1>
        <h3 id="profile-resume"></h3>
      </a>

      <hr class="divider long">
      <p>I'm a PhD student in Natural Language Processing and a research scientist at AYLIEN. I blog about Machine Learning, Deep Learning, NLP, and startups.</p>
      <hr class="divider short">
      <div class="navigation">
        <div class="profile contact">
          <nav class="navigation left">
  <ul class="links">
      <li class="nav-blog ">
        <a href="http://ruder.io/">Blog</a>
      </li>
      <li class="nav-about ">
        <a href="http://ruder.io/about/">About</a>
      </li>
      <li class="nav-papers ">
        <a href="http://ruder.io/publications/">Papers</a>
      </li>
      <li class="nav-news ">
        <a href="http://ruder.io/news">News</a>
      </li>
      <li class="nav-newsletter ">
        <a href="http://newsletter.ruder.io">Newsletter</a>
      </li>
      <li class="nav-faq ">
        <a href="http://ruder.io/faq">FAQ</a>
      </li>
  </ul>
</nav>

          
<nav class="navigation right">
  <ul class="social expanded">

  <!-- Twitter -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="http://twitter.com/seb_ruder" title="@seb_ruder on Twitter">
      <i class="icon icon-social-twitter"></i>
      <span class="label">Twitter</span>
    </a>
  </li>

  <!-- Linkedin -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://www.linkedin.com/in/sebastianruder" title="sebastianruder on LinkedIn">
      <i class="icon icon-social-linkedin"></i>
      <span class="label">Linkedin</span>
    </a>
  </li>

  <!-- Github -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://github.com/sebastianruder" title="sebastianruder on Github">
      <i class="icon icon-social-github"></i>
      <span class="label">Github</span>
    </a>
  </li>

  <!-- E-mail -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="mailto:sebastian@ruder.io" title="send me an email">
      <i class="icon icon-mail"></i>
      <span class="label">Email</span>
    </a>
  </li>

  <!-- RSS -->
  <li class="social item hvr-grow-rotate">
    <a href="../rss/index.rss" title="Subscribe to RSS">
      <i class="icon icon-rss"></i>
      <span class="label">RSS</span>
    </a>
  </li>

  </ul>
</nav>
          <section class="icon icon-search" id="search-container">
  <hr class="divider short">
  <form id="search-form" action="https://www.google.com/#q=site:u=http://ruder.io">
    <input type="text" name="search" placeholder="Deep Learning, NLP, ..." id="search-field">
  </form>
</section>
        </div>
      </div>
    </div>
  </div>
</aside>
    <main>
      <section id="search-results"></section>
      <section class="content">
        

  <article class="post tag-deep-learning tag-nlp tag-transfer-learning">
    <header>
      <div class="post meta">
        <time datetime="04 Mar 2018">04 Mar 2018</time>
        <span class="post tags">in <a href="../tag/deep-learning/">deep learning</a> <a href="../tag/nlp/">nlp</a> <a href="../tag/transfer-learning/">transfer learning</a></span>


        <span class="post reading-time"> ~ <span></span> read.</span>
      </div>
      <a alt="Tweet 'Requests for Research'" href="https://twitter.com/intent/tweet?text=Requests%20for%20Research%20%C2%BB&amp;hashtags=deep%20learning,nlp,transfer%20learning&amp;url=http://ruder.io/requests-for-research/">
        
        <h1 class="icon-reverse icon-social-twitter-post" id="post-title">Requests for Research</h1>
      </a>
    </header>

    <div id="post-content" class="post tag-deep-learning tag-nlp tag-transfer-learning">
      <p>Table of contents:</p>

<ul>
<li><a href="index.html#taskindependentdataaugmentationfornlp">Task-independent data augmentation for NLP</a></li>
<li><a href="index.html#fewshotlearningfornlp">Few-shot learning for NLP</a></li>
<li><a href="index.html#transferlearningfornlp">Transfer learning for NLP</a></li>
<li><a href="index.html#multitasklearning">Multi-task learning</a></li>
<li><a href="index.html#crosslinguallearning">Cross-lingual learning</a></li>
<li><a href="index.html#taskindependentarchitectureimprovements">Task-independent architecture improvements</a></li>
</ul>

<p>It can be hard to find compelling topics to work on and know what questions are interesting to ask when you are just starting as a researcher in a new field. Machine learning research in particular moves so fast these days that it is difficult to find an opening.</p>

<p>This post aims to provide inspiration and ideas for research directions to junior researchers and those trying to get into research. It gathers a collection of research topics that are interesting to me, with a focus on NLP and transfer learning. As such, they might obviously not be of interest to everyone. If you are interested in Reinforcement Learning, OpenAI provides a <a href="https://blog.openai.com/requests-for-research-2/">selection of interesting RL-focused research topics</a>. In case you'd like to collaborate with others or are interested in a broader range of topics, have a look at the <a href="https://ai-on.org/">Artificial Intelligence Open Network</a>.</p>

<p>Most of these topics are not thoroughly thought out yet; in many cases, the general description is quite vague and subjective and many directions are possible. In addition, most of these are <em>not</em> low-hanging fruit, so serious effort is necessary to come up with a solution. I am happy to provide feedback with regard to any of these, but will not have time to provide more detailed guidance unless you have a working proof-of-concept. I will update this post periodically with new research directions and advances in already listed ones. Note that this collection does not attempt to review the extensive literature but only aims to give a glimpse of a topic; consequently, the references won't be comprehensive.</p>

<p>I hope that this collection will pique your interest and serve as inspiration for your own research agenda.</p>

<h2 id="taskindependentdataaugmentationfornlp"> Task-independent data augmentation for NLP</h2>

<p>Data augmentation aims to create additional training data by producing variations of existing training examples through transformations, which can mirror those encountered in the real world. In Computer Vision (CV), common augmentation techniques are <a href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/AYzbX/data-augmentation">mirroring, random cropping, shearing, etc</a>. Data augmentation is super useful in CV. For instance, it has been used to great effect in AlexNet (Krizhevsky et al., 2012) [<sup id="fnref:1"><a href="index.html#fn:1" rel="footnote">1</a></sup>] to combat overfitting and in most state-of-the-art models since. In addition, data augmentation makes intuitive sense as it makes the training data more diverse and should thus increase a model's generalization ability.</p>

<p>However, in NLP, data augmentation is not widely used. In my mind, this is for two reasons:</p>

<ol>
<li>Data in NLP is discrete. This prevents us from applying simple transformations directly to the input data. Most recently proposed augmentation methods in CV focus on such transformations, e.g. domain randomization (Tobin et al., 2017) [<sup id="fnref:2"><a href="index.html#fn:2" rel="footnote">2</a></sup>].  </li>
<li>Small perturbations may change the meaning. Deleting a negation may change a sentence's sentiment, while modifying a word in a paragraph might inadvertently change the answer to a question about that paragraph. This is not the case in CV where perturbing individual pixels does not change whether an image is a cat or dog and even stark changes such as interpolation of different images can be useful (Zhang et al., 2017) [<sup id="fnref:3"><a href="index.html#fn:3" rel="footnote">3</a></sup>].</li>
</ol>

<p>Existing approaches that I am aware of are either rule-based (Li et al., 2017) [<sup id="fnref:5"><a href="index.html#fn:5" rel="footnote">5</a></sup>] or task-specific, e.g. for parsing (Wang and Eisner, 2016) [<sup id="fnref:6"><a href="index.html#fn:6" rel="footnote">6</a></sup>] or zero-pronoun resolution (Liu et al., 2017) [<sup id="fnref:7"><a href="index.html#fn:7" rel="footnote">7</a></sup>]. Xie et al. (2017) [<sup id="fnref:39"><a href="index.html#fn:39" rel="footnote">39</a></sup>] replace words with samples from different distributions for language modelling and Machine Translation. Recent work focuses on creating adversarial examples either by replacing words or characters (Samanta and Mehta, 2017; Ebrahimi et al., 2017) [<sup id="fnref:8"><a href="index.html#fn:8" rel="footnote">8</a></sup>, <sup id="fnref:9"><a href="index.html#fn:9" rel="footnote">9</a></sup>], concatenation (Jia and Liang, 2017) [<sup id="fnref:11"><a href="index.html#fn:11" rel="footnote">11</a></sup>], or adding adversarial perturbations (Yasunaga et al., 2017) [<sup id="fnref:10"><a href="index.html#fn:10" rel="footnote">10</a></sup>]. An adversarial setup is also used by Li et al. (2017) [<sup id="fnref:16"><a href="index.html#fn:16" rel="footnote">16</a></sup>] who train a system to produce sequences that are indistinguishable from human-generated dialogue utterances.</p>

<p>Back-translation (Sennrich et al., 2015; Sennrich et al., 2016) [<sup id="fnref:12"><a href="index.html#fn:12" rel="footnote">12</a></sup>, <sup id="fnref:13"><a href="index.html#fn:13" rel="footnote">13</a></sup>] is a common data augmentation method in Machine Translation (MT) that allows us to incorporate monolingual training data. For instance, when training a EN\(\rightarrow\)FR system, monolingual French text is translated to English using an FR\(\rightarrow\)EN system; the synthetic parallel data can then be used for training. Back-translation can also be used for paraphrasing (Mallinson et al., 2017) [<sup id="fnref:14"><a href="index.html#fn:14" rel="footnote">14</a></sup>]. Paraphrasing has been used for data augmentation for QA (Dong et al., 2017) [<sup id="fnref:15"><a href="index.html#fn:15" rel="footnote">15</a></sup>], but I am not aware of its use for other tasks.</p>

<p>Another method that is close to paraphrasing is generating sentences from a continuous space using a variational autoencoder (Bowman et al., 2016; Guu et al., 2017) [<sup id="fnref:17"><a href="index.html#fn:17" rel="footnote">17</a></sup>, <sup id="fnref:19"><a href="index.html#fn:19" rel="footnote">19</a></sup>]. If the representations are disentangled as in (Hu et al., 2017) [<sup id="fnref:18"><a href="index.html#fn:18" rel="footnote">18</a></sup>], then we are also not too far from style transfer (Shen et al., 2017) [<sup id="fnref:20"><a href="index.html#fn:20" rel="footnote">20</a></sup>].</p>

<p>There are a few research directions that would be interesting to pursue:</p>

<ol>
<li><strong>Evaluation study:</strong> Evaluate a range of existing data augmentation methods as well as techniques that have not been widely used for augmentation such as paraphrasing and style transfer on a diverse range of tasks including text classification and sequence labelling. Identify what types of data augmentation are robust across task and which are task-specific. This could be packaged as a software library to make future benchmarking easier (think <a href="https://github.com/tensorflow/cleverhans">CleverHans</a> for NLP).  </li>
<li><strong>Data augmentation with style transfer:</strong> Investigate if style transfer can be used to modify various attributes of training examples for more robust learning.  </li>
<li><strong>Learn the augmentation:</strong> Similar to Dong et al. (2017) we could learn either to paraphrase or to generate transformations for a particular task.  </li>
<li><strong>Learn a word embedding space for data augmentation:</strong> A typical word embedding space clusters synonyms and antonyms together; using nearest neighbours in this space for replacement is thus infeasible. Inspired by recent work (Mrkšić et al., 2017) [<sup id="fnref:21"><a href="index.html#fn:21" rel="footnote">21</a></sup>], we could specialize the word embedding space to make it more suitable for data augmentation.  </li>
<li><strong>Adversarial data augmentation:</strong> Related to recent work in interpretability (Ribeiro et al., 2016) [<sup id="fnref:22"><a href="index.html#fn:22" rel="footnote">22</a></sup>], we could change the most salient words in an example, i.e. those that a model depends on for a prediction. This still requires a semantics-preserving replacement method, however.</li>
</ol>

<h2 id="fewshotlearningfornlp"> Few-shot learning for NLP</h2>

<p>Zero-shot, one-shot and few-shot learning are one of the most interesting recent research directions IMO. Following the key insight from Vinyals et al. (2016) [<sup id="fnref:4"><a href="index.html#fn:4" rel="footnote">4</a></sup>] that a few-shot learning model should be explicitly trained to perform few-shot learning, we have seen several recent advances (Ravi and Larochelle, 2017; Snell et al., 2017) [<sup id="fnref:23"><a href="index.html#fn:23" rel="footnote">23</a></sup>, <sup id="fnref:24"><a href="index.html#fn:24" rel="footnote">24</a></sup>]. </p>

<p>Learning from few labeled samples is one of the hardest problems IMO and one of the core capabilities that separates the current generation of ML models from more generally applicable systems. Zero-shot learning has only been investigated in the context of <a href="http://ruder.io/word-embeddings-2017/index.html#oovhandling">learning word embeddings for unknown words</a> AFAIK. Dataless classification (Song and Roth, 2014; Song et al., 2016) [<sup id="fnref:25"><a href="index.html#fn:25" rel="footnote">25</a></sup>, <sup id="fnref:26"><a href="index.html#fn:26" rel="footnote">26</a></sup>] is an interesting related direction that embeds labels and documents in a joint space, but requires interpretable labels with good descriptions. </p>

<p>Potential research directions are the following:</p>

<ol>
<li><strong>Standardized benchmarks:</strong> Create standardized benchmarks for few-shot learning for NLP. Vinyals et al. (2016) introduce a one-shot language modelling task for the Penn Treebank. The task, while useful, is dwarfed by the extensive evaluation on CV benchmarks and has not seen much use AFAIK. A few-shot learning benchmark for NLP should contain a large number of classes and provide a standardized split for reproducibility. Good candidate tasks would be topic classification or fine-grained entity recognition.  </li>
<li><strong>Evaluation study</strong>: After creating such a benchmark, the next step would be to evaluate how well existing few-shot learning models from CV perform for NLP.  </li>
<li><strong>Novel methods for NLP</strong>: Given a dataset for benchmarking and an empirical evaluation study, we could then start developing novel methods that can perform few-shot learning for NLP.</li>
</ol>

<h2 id="transferlearningfornlp"> Transfer learning for NLP</h2>

<p>Transfer learning has had a large impact on computer vision (CV) and has greatly lowered the entry threshold for people wanting to apply CV algorithms to their own problems. CV practicioners are no longer required to perform extensive feature-engineering for every new task, but can simply fine-tune a model pretrained on a large dataset with a small number of examples.</p>

<p>In NLP, however, we have so far only been pretraining the first layer of our models via pretrained embeddings. Recent approaches (Peters et al., 2017, 2018) [<sup id="fnref:31"><a href="index.html#fn:31" rel="footnote">31</a></sup>, <sup id="fnref:32"><a href="index.html#fn:32" rel="footnote">32</a></sup>] add pretrained language model embedddings, but these still require custom architectures for every task. In my opinion, in order to unlock the true potential of transfer learning for NLP, we need to pretrain the entire model and fine-tune it on the target task, akin to fine-tuning ImageNet models. Language modelling, for instance, is a great task for pretraining and could be to NLP what ImageNet classification is to CV (Howard and Ruder, 2018) [<sup id="fnref:33"><a href="index.html#fn:33" rel="footnote">33</a></sup>].</p>

<p>Here are some potential research directions in this context:</p>

<ol>
<li><strong>Identify useful pretraining tasks:</strong> The choice of the pretraining task is very important as even fine-tuning a model on a related task might only provide limited success (Mou et al., 2016) [<sup id="fnref:38"><a href="index.html#fn:38" rel="footnote">38</a></sup>]. Other tasks such as those explored in recent work on learning general-purpose sentence embeddings (Conneau et al., 2017; Subramanian et al., 2018; Nie et al., 2017) [<sup id="fnref:34"><a href="index.html#fn:34" rel="footnote">34</a></sup>, <sup id="fnref:35"><a href="index.html#fn:35" rel="footnote">35</a></sup>, <sup id="fnref:40"><a href="index.html#fn:40" rel="footnote">40</a></sup>] might be complementary to language model pretraining or suitable for other target tasks.  </li>
<li><strong>Fine-tuning of complex architectures:</strong> Pretraining is most useful when a model can be applied to many target tasks. However, it is still unclear how to pretrain more complex architectures, such as those used for pairwise classification tasks (Augenstein et al., 2018) or reasoning tasks such as QA or reading comprehension.</li>
</ol>

<h2 id="multitasklearning"> Multi-task learning</h2>

<p>Multi-task learning (MTL) has become more commonly used in NLP. See <a href="http://ruder.io/multi-task/">here</a> for a general overview of multi-task learning and <a href="http://ruder.io/multi-task-learning-nlp/">here</a> for MTL objectives for NLP. However, there is still much we don't understand about multi-task learning in general.</p>

<p>The main questions regarding MTL give rise to many interesting research directions:</p>

<ol>
<li><strong>Identify effective auxiliary tasks:</strong> One of the main questions is which tasks are useful for multi-task learning. Label entropy has been shown to be a predictor of MTL success (Alonso and Plank, 2017) [<sup id="fnref:28"><a href="index.html#fn:28" rel="footnote">28</a></sup>], but this does not tell the whole story. In recent work (Augenstein et al., 2018) [<sup id="fnref:27"><a href="index.html#fn:27" rel="footnote">27</a></sup>], we have found that auxiliary tasks with more data and more fine-grained labels are more useful. It would be useful if future MTL papers would not only propose a new model or auxiliary task, but also try to understand why a certain auxiliary task might be better than another closely related one.  </li>
<li><strong>Alternatives to hard parameter sharing:</strong> Hard parameter sharing is still the default modus operandi for MTL, but places a strong constraint on the model to compress knowledge pertaining to different tasks with the same parameters, which often makes learning difficult. We need better ways of doing MTL that are easy to use and work reliably across many tasks. Recently proposed methods such as cross-stitch units (Misra et al., 2017; Ruder et al., 2017) [<sup id="fnref:29"><a href="index.html#fn:29" rel="footnote">29</a></sup>, <sup id="fnref:30"><a href="index.html#fn:30" rel="footnote">30</a></sup>] and a label embedding layer (Augenstein et al., 2018) are promising steps in this direction.  </li>
<li><strong>Artificial auxiliary tasks:</strong> The best auxiliary tasks are those, which are tailored to the target task and do not require any additional data. I have outlined a list of potential <em>artificial</em> auxiliary tasks <a href="http://ruder.io/multi-task-learning-nlp/">here</a>. However, it is not clear which of these work reliably across a number of diverse tasks or what variations or task-specific modifications are useful.</li>
</ol>

<h2 id="crosslinguallearning"> Cross-lingual learning</h2>

<p>Creating models that perform well across languages and that can transfer knowledge from resource-rich to resource-poor languages is one of the most important research directions IMO. There has been much progress in learning cross-lingual representations that project different languages into a shared embedding space. Refer to Ruder et al. (2017) [<sup id="fnref:36"><a href="index.html#fn:36" rel="footnote">36</a></sup>] for a survey.</p>

<p>Cross-lingual representations are commonly evaluated either intrinsically on similarity benchmarks or extrinsically on downstream tasks, such as text classification. While recent methods have advanced the state-of-the-art for many of these settings, we do not have a good understanding of the tasks or languages for which these methods fail and how to mitigate these failures in a task-independent manner, e.g. by injecting task-specific constraints (Mrkšić et al., 2017).</p>

<h2 id="taskindependentarchitectureimprovements"> Task-independent architecture improvements</h2>

<p>Novel architectures that outperform the current state-of-the-art and are tailored to specific tasks are regularly introduced, superseding the previous architecture. I have outlined <a href="http://ruder.io/deep-learning-nlp-best-practices/">best practices for different NLP tasks</a> before, but without comparing such architectures on different tasks, it is often hard to gain insights from specialized architectures and tell which components would also be useful in other settings. </p>

<p>A particularly promising recent model is the Transformer (Vaswani et al., 2017) [<sup id="fnref:37"><a href="index.html#fn:37" rel="footnote">37</a></sup>]. While the complete model might not be appropriate for every task, components such as multi-head attention or position-based encoding could be building blocks that are generally useful for many NLP tasks.</p>

<h2 id="conclusion"> Conclusion</h2>

<p>I hope you've found this collection of research directions useful. If you have suggestions on how to tackle some of these problems or ideas for related research topics, feel free to comment below.</p>

<h2 id="references"> References</h2>

<div class="footnotes"><ol><li class="footnote" id="fn:1"><p>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105). <a href="index.html#fnref:1" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:2"><p>Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., &amp; Abbeel, P. (2017). Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. arXiv Preprint arXiv:1703.06907. Retrieved from <a href="http://arxiv.org/abs/1703.06907">http://arxiv.org/abs/1703.06907</a> <a href="index.html#fnref:2" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:3"><p>Zhang, H., Cisse, M., Dauphin, Y. N., &amp; Lopez-Paz, D. (2017). mixup: Beyond Empirical Risk Minimization, 1–11. Retrieved from <a href="http://arxiv.org/abs/1710.09412">http://arxiv.org/abs/1710.09412</a> <a href="index.html#fnref:3" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:4"><p>Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., &amp; Wierstra, D. (2016). Matching Networks for One Shot Learning. NIPS 2016. Retrieved from <a href="http://arxiv.org/abs/1606.04080">http://arxiv.org/abs/1606.04080</a> <a href="index.html#fnref:4" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:5"><p>Li, Y., Cohn, T., &amp; Baldwin, T. (2017). Robust Training under Linguistic Adversity. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (Vol. 2, pp. 21–27). <a href="index.html#fnref:5" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:6"><p>Wang, D., &amp; Eisner, J. (2016). The Galactic Dependencies Treebanks: Getting More Data by Synthesizing New Languages. Tacl, 4, 491–505. Retrieved from <a href="https://www.transacl.org/ojs/index.php/tacl/article/viewFile/917/212%0Ahttps://transacl.org/ojs/index.php/tacl/article/view/917">https://www.transacl.org/ojs/index.php/tacl/article/viewFile/917/212%0Ahttps://transacl.org/ojs/index.php/tacl/article/view/917</a> <a href="index.html#fnref:6" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:7"><p>Liu, T., Cui, Y., Yin, Q., Zhang, W., Wang, S., &amp; Hu, G. (2017). Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun Resolution. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (pp. 102–111). <a href="index.html#fnref:7" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:8"><p>Samanta, S., &amp; Mehta, S. (2017). Towards Crafting Text Adversarial Samples. arXiv preprint arXiv:1707.02812. <a href="index.html#fnref:8" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:9"><p>Ebrahimi, J., Rao, A., Lowd, D., &amp; Dou, D. (2017). HotFlip: White-Box Adversarial Examples for NLP. Retrieved from <a href="http://arxiv.org/abs/1712.06751">http://arxiv.org/abs/1712.06751</a> <a href="index.html#fnref:9" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:10"><p>Yasunaga, M., Kasai, J., &amp; Radev, D. (2017). Robust Multilingual Part-of-Speech Tagging via Adversarial Training. In Proceedings of NAACL 2018. Retrieved from <a href="http://arxiv.org/abs/1711.04903">http://arxiv.org/abs/1711.04903</a> <a href="index.html#fnref:10" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:11"><p>Jia, R., &amp; Liang, P. (2017). Adversarial Examples for Evaluating Reading Comprehension Systems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. <a href="index.html#fnref:11" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:12"><p>Sennrich, R., Haddow, B., &amp; Birch, A. (2015). Improving neural machine translation models with monolingual data. arXiv preprint arXiv:1511.06709. <a href="index.html#fnref:12" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:13"><p>Sennrich, R., Haddow, B., &amp; Birch, A. (2016). Edinburgh neural machine translation systems for wmt 16. arXiv preprint arXiv:1606.02891. <a href="index.html#fnref:13" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:14"><p>Mallinson, J., Sennrich, R., &amp; Lapata, M. (2017). Paraphrasing revisited with neural machine translation. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers (Vol. 1, pp. 881-893). <a href="index.html#fnref:14" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:15"><p>Dong, L., Mallinson, J., Reddy, S., &amp; Lapata, M. (2017). Learning to Paraphrase for Question Answering. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. <a href="index.html#fnref:15" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:16"><p>Li, J., Monroe, W., Shi, T., Ritter, A., &amp; Jurafsky, D. (2017). Adversarial Learning for Neural Dialogue Generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Retrieved from <a href="http://arxiv.org/abs/1701.06547">http://arxiv.org/abs/1701.06547</a> <a href="index.html#fnref:16" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:17"><p>Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Jozefowicz, R., &amp; Bengio, S. (2016). Generating Sentences from a Continuous Space. In Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL). Retrieved from <a href="http://arxiv.org/abs/1511.06349">http://arxiv.org/abs/1511.06349</a> <a href="index.html#fnref:17" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:18"><p>Hu, Z., Yang, Z., Liang, X., Salakhutdinov, R., &amp; Xing, E. P. (2017). Toward Controlled Generation of Text. In Proceedings of the 34th International Conference on Machine Learning. <a href="index.html#fnref:18" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:19"><p>Guu, K., Hashimoto, T. B., Oren, Y., &amp; Liang, P. (2017). Generating Sentences by Editing Prototypes. <a href="index.html#fnref:19" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:20"><p>Shen, T., Lei, T., Barzilay, R., &amp; Jaakkola, T. (2017). Style Transfer from Non-Parallel Text by Cross-Alignment. In Advances in Neural Information Processing Systems. Retrieved from <a href="http://arxiv.org/abs/1705.09655">http://arxiv.org/abs/1705.09655</a> <a href="index.html#fnref:20" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:21"><p>Mrkšić, N., Vulić, I., Séaghdha, D. Ó., Leviant, I., Reichart, R., Gašić, M., … Young, S. (2017). Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints. TACL. Retrieved from <a href="http://arxiv.org/abs/1706.00374">http://arxiv.org/abs/1706.00374</a> <a href="index.html#fnref:21" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:22"><p>Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016, August). Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1135-1144). ACM. <a href="index.html#fnref:22" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:23"><p>Ravi, S., &amp; Larochelle, H. (2017). Optimization as a Model for Few-Shot Learning. In ICLR 2017. <a href="index.html#fnref:23" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:24"><p>Snell, J., Swersky, K., &amp; Zemel, R. S. (2017). Prototypical Networks for Few-shot Learning. In Advances in Neural Information Processing Systems. <a href="index.html#fnref:24" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:25"><p>Song, Y., &amp; Roth, D. (2014). On dataless hierarchical text classification. Proceedings of AAAI, 1579–1585. Retrieved from <a href="http://cogcomp.cs.illinois.edu/papers/SongSoRo14.pdf">http://cogcomp.cs.illinois.edu/papers/SongSoRo14.pdf</a> <a href="index.html#fnref:25" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:26"><p>Song, Y., Upadhyay, S., Peng, H., &amp; Roth, D. (2016). Cross-Lingual Dataless Classification for Many Languages. Ijcai, 2901–2907. <a href="index.html#fnref:26" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:27"><p>Augenstein, I., Ruder, S., &amp; Søgaard, A. (2018). Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces. In Proceedings of NAACL 2018. <a href="index.html#fnref:27" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:28"><p>Alonso, H. M., &amp; Plank, B. (2017). When is multitask learning effective? Multitask learning for semantic sequence prediction under varying data conditions. In EACL. Retrieved from <a href="http://arxiv.org/abs/1612.02251">http://arxiv.org/abs/1612.02251</a> <a href="index.html#fnref:28" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:29"><p>Misra, I., Shrivastava, A., Gupta, A., &amp; Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. <a href="http://doi.org/10.1109/CVPR.2016.433">http://doi.org/10.1109/CVPR.2016.433</a> <a href="index.html#fnref:29" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:30"><p>Ruder, S., Bingel, J., Augenstein, I., &amp; Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. arXiv preprint arXiv:1705.08142. <a href="index.html#fnref:30" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:31"><p>Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017). <a href="index.html#fnref:31" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:32"><p>Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). Deep contextualized word representations. Proceedings of NAACL. <a href="index.html#fnref:32" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:33"><p>Howard, J., &amp; Ruder, S. (2018). Fine-tuned Language Models for Text Classification. arXiv preprint arXiv:1801.06146. <a href="index.html#fnref:33" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:34"><p>Conneau, A., Kiela, D., Schwenk, H., Barrault, L., &amp; Bordes, A. (2017). Supervised Learning of Universal Sentence Representations from Natural Language Inference Data. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. <a href="index.html#fnref:34" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:35"><p>Subramanian, S., Trischler, A., Bengio, Y., &amp; Pal, C. J. (2018). Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning. In Proceedings of ICLR 2018. <a href="index.html#fnref:35" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:36"><p>Ruder, S., Vulić, I., &amp; Søgaard, A. (2017). A Survey of Cross-lingual Word Embedding Models. arXiv Preprint arXiv:1706.04902. Retrieved from <a href="http://arxiv.org/abs/1706.04902">http://arxiv.org/abs/1706.04902</a> <a href="index.html#fnref:36" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:37"><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). Attention Is All You Need. In Advances in Neural Information Processing Systems. <a href="index.html#fnref:37" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:38"><p>Mou, L., Meng, Z., Yan, R., Li, G., Xu, Y., Zhang, L., &amp; Jin, Z. (2016). How Transferable are Neural Networks in NLP Applications? Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing. <a href="index.html#fnref:38" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:39"><p>Xie, Z., Wang, S. I., Li, J., Levy, D., Nie, A., Jurafsky, D., &amp; Ng, A. Y. (2017). Data Noising as Smoothing in Neural Network Language Models. In Proceedings of ICLR 2017. <a href="index.html#fnref:39" title="return to article">↩</a></p></li>

<li class="footnote" id="fn:40"><p>Nie, A., Bennett, E. D., &amp; Goodman, N. D. (2017). DisSent: Sentence Representation Learning from Explicit Discourse Relations. arXiv Preprint arXiv:1710.04334. Retrieved from <a href="http://arxiv.org/abs/1710.04334">http://arxiv.org/abs/1710.04334</a> <a href="index.html#fnref:40" title="return to article">↩</a></p></li></ol></div>
    </div>

    <div class="post related">
        <a rel="prev" id="prev-btn" class="btn small square" href="../deep-learning-optimization-2017/">← Optimization for Deep Learning Highlights in 2017</a>

        <a rel="next" id="next-btn" class="btn small square" href="../text-classification-tensorflow-estimators/">Text Classification with TensorFlow Estimators →</a>
    </div>

    <footer class="post comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
  (function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + window.disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</footer>

  </article>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>  

        <footer>
  <span class="copyright">
    © 2018. All rights reserved. Built with <a href="https://ghost.org/" target="_blank">Ghost</a> and <a href="https://github.com/Kikobeats/uno-zen" target="_blank">Uno Zen</a> theme.
  </span>
</footer>
      </section>
    </main>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
<script>jQuery = Zepto</script>
    <script src="../assets/js/uno-zen.js?v=eab98792e1" type="text/javascript" charset="utf-8"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>
  if (window.ga_id) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', window.ga_id, 'auto');
    ga('require', 'linkid', 'linkid.js');
    ga('send', 'pageview');
  }
</script>
  </body>
