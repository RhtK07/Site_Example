
  <head>
    <title>Highlights of EMNLP 2016: Dialogue, deep learning, and more</title>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1">



<link rel="apple-touch-icon" sizes="57x57" href="../assets/img/apple-touch-icon-57x57.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="60x60" href="../assets/img/apple-touch-icon-60x60.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="72x72" href="../assets/img/apple-touch-icon-72x72.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="76x76" href="../assets/img/apple-touch-icon-76x76.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="114x114" href="../assets/img/apple-touch-icon-114x114.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="120x120" href="../assets/img/apple-touch-icon-120x120.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="144x144" href="../assets/img/apple-touch-icon-144x144.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="152x152" href="../assets/img/apple-touch-icon-152x152.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="180x180" href="../assets/img/apple-touch-icon-180x180.png?v=wAAv6Wqe6l">
<link rel="icon" type="image/png" href="../assets/img/favicon-32x32.png?v=wAAv6Wqe6l" sizes="32x32">
<link rel="icon" type="image/png" href="../assets/img/favicon-194x194.png?v=wAAv6Wqe6l" sizes="194x194">
<link rel="icon" type="image/png" href="../assets/img/favicon-96x96.png?v=wAAv6Wqe6l" sizes="96x96">
<link rel="icon" type="image/png" href="../assets/img/android-chrome-192x192.png?v=wAAv6Wqe6l" sizes="192x192">
<link rel="icon" type="image/png" href="../assets/img/favicon-16x16.png?v=wAAv6Wqe6l" sizes="16x16">
<link rel="manifest" href="../assets/img/manifest.json?v=wAAv6Wqe6l">
<link rel="shortcut icon" href="../assets/img/favicon.ico?v=wAAv6Wqe6l">
<meta name="msapplication-TileColor" content="#e74c3c">
<meta name="msapplication-TileImage" content="/assets/img/mstile-144x144.png?v=wAAv6Wqe6l">
<meta name="msapplication-config" content="/assets/img/browserconfig.xml?v=wAAv6Wqe6l">
<meta name="theme-color" content="#e74c3c">
    <link rel="stylesheet" type="text/css" href="../assets/css/uno-zen.css?v=35ddfd5849">
    <link rel="canonical" href="http://ruder.io/emnlp-2016-highlights/">
    <meta name="referrer" content="origin">
    
    <meta property="og:site_name" content="Sebastian Ruder">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Highlights of EMNLP 2016: Dialogue, deep learning, and more">
    <meta property="og:description" content="This post originally appeared on the AYLIEN blog. I spent the past week in Austin, Texas at EMNLP 2016, the Conference on Empirical Methods in Natural Language Processing. There were a lot of papers at the conference (179 long papers,...">
    <meta property="og:url" content="u=http://ruder.io/emnlp-2016-highlights/">
    <meta property="og:image" content="u=http://ruder.io/content/images/2016/11/emnlp_cover_image.jpg">
    <meta property="article:published_time" content="2016-11-14T12:00:00.000Z">
    <meta property="article:modified_time" content="2016-11-21T11:16:23.515Z">
    <meta property="article:tag" content="natural language processing">
    <meta property="article:tag" content="deep learning">
    <meta property="article:tag" content="machine learning">
    <meta property="article:tag" content="word embeddings">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Highlights of EMNLP 2016: Dialogue, deep learning, and more">
    <meta name="twitter:description" content="This post originally appeared on the AYLIEN blog. I spent the past week in Austin, Texas at EMNLP 2016, the Conference on Empirical Methods in Natural Language Processing. There were a lot of papers at the conference (179 long papers,...">
    <meta name="twitter:url" content="u=http://ruder.io/emnlp-2016-highlights/">
    <meta name="twitter:image:src" content="u=http://ruder.io/content/images/2016/11/emnlp_cover_image.jpg">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Sebastian Ruder",
    "author": {
        "@type": "Person",
        "name": "Sebastian Ruder",
        "url": "u=http://ruder.io/author/sebastian",
        "sameAs": null,
        "description": null
    },
    "headline": "Highlights of EMNLP 2016: Dialogue, deep learning, and more",
    "url": "u=http://ruder.io/emnlp-2016-highlights/",
    "datePublished": "2016-11-14T12:00:00.000Z",
    "dateModified": "2016-11-21T11:16:23.515Z",
    "image": "u=http://ruder.io/content/images/2016/11/emnlp_cover_image.jpg",
    "keywords": "natural language processing, deep learning, machine learning, word embeddings",
    "description": "This post originally appeared on the AYLIEN blog. I spent the past week in Austin, Texas at EMNLP 2016, the Conference on Empirical Methods in Natural Language Processing. There were a lot of papers at the conference (179 long papers,..."
}
    </script>

    <meta name="generator" content="Ghost 0.7">
    <link rel="alternate" type="application/rss+xml" title="Sebastian Ruder" href="http://ruder.io/rss/">
    <script>
var open_button = '.nav-blog > a'
</script>
<script>
var profile_title = 'Sebastian Ruder';
</script>
<script>
var disqus_shortname = 'sebastianruder';
</script>
<script>
var profile_resume ='NLP PhD student';
</script>
<script>
var ga_id = 'UA-60512592-1';
</script>
  </head>
  <body class="post-template tag-natural-language-processing tag-deep-learning tag-machine-learning tag-word-embeddings">
    <header id="menu-button" class="expanded">
      <a><i class="icon icon-list"></i></a>
    </header>
    <aside class="cover" style="background: url(../content/images/2017/05/imageedit_8_8459453433.jpg) center/cover no-repeat fixed">
  <div class="cover container">
    <div class="profile">
      <a id="avatar-link" title="link to homepage for Sebastian Ruder" href="http://ruder.io/#open">
        <img src="../content/images/2015/12/Seb_LinkedIn_Profile-.png" alt="Sebastian Ruder avatar" class="profile avatar rounded hvr-buzz-out">
        <h1 id="profile-title">Sebastian Ruder</h1>
        <h3 id="profile-resume"></h3>
      </a>

      <hr class="divider long">
      <p>I'm a PhD student in Natural Language Processing and a research scientist at AYLIEN. I blog about Machine Learning, Deep Learning, NLP, and startups.</p>
      <hr class="divider short">
      <div class="navigation">
        <div class="profile contact">
          <nav class="navigation left">
  <ul class="links">
      <li class="nav-blog ">
        <a href="http://ruder.io/">Blog</a>
      </li>
      <li class="nav-about ">
        <a href="http://ruder.io/about/">About</a>
      </li>
      <li class="nav-papers ">
        <a href="http://ruder.io/publications/">Papers</a>
      </li>
      <li class="nav-news ">
        <a href="http://ruder.io/news">News</a>
      </li>
      <li class="nav-newsletter ">
        <a href="http://newsletter.ruder.io">Newsletter</a>
      </li>
      <li class="nav-faq ">
        <a href="http://ruder.io/faq">FAQ</a>
      </li>
      <li class="nav-progress ">
        <a href="https://nlpprogress.com/">Progress</a>
      </li>
  </ul>
</nav>

          
<nav class="navigation right">
  <ul class="social expanded">

  <!-- Twitter -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="http://twitter.com/seb_ruder" title="@seb_ruder on Twitter">
      <i class="icon icon-social-twitter"></i>
      <span class="label">Twitter</span>
    </a>
  </li>

  <!-- Linkedin -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://www.linkedin.com/in/sebastianruder" title="sebastianruder on LinkedIn">
      <i class="icon icon-social-linkedin"></i>
      <span class="label">Linkedin</span>
    </a>
  </li>

  <!-- Github -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://github.com/sebastianruder" title="sebastianruder on Github">
      <i class="icon icon-social-github"></i>
      <span class="label">Github</span>
    </a>
  </li>

  <!-- E-mail -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="mailto:sebastian@ruder.io" title="send me an email">
      <i class="icon icon-mail"></i>
      <span class="label">Email</span>
    </a>
  </li>

  <!-- RSS -->
  <li class="social item hvr-grow-rotate">
    <a href="../rss/index.rss" title="Subscribe to RSS">
      <i class="icon icon-rss"></i>
      <span class="label">RSS</span>
    </a>
  </li>

  </ul>
</nav>
          <section class="icon icon-search" id="search-container">
  <hr class="divider short">
  <form id="search-form" action="https://www.google.com/#q=site:u=http://ruder.io">
    <input type="text" name="search" placeholder="Deep Learning, NLP, ..." id="search-field">
  </form>
</section>
        </div>
      </div>
    </div>
  </div>
</aside>
    <main>
      <section id="search-results"></section>
      <section class="content">
        

  <article class="post tag-natural-language-processing tag-deep-learning tag-machine-learning tag-word-embeddings">
    <header>
      <div class="post meta">
        <time datetime="14 Nov 2016">14 Nov 2016</time>
        <span class="post tags">in <a href="../tag/natural-language-processing/">natural language processing</a> <a href="../tag/deep-learning/">deep learning</a> <a href="../tag/machine-learning/">machine learning</a> <a href="../tag/word-embeddings/">word embeddings</a></span>


        <span class="post reading-time"> ~ <span></span> read.</span>
      </div>
      <a alt="Tweet 'Highlights of EMNLP 2016: Dialogue, deep learning, and more'" href="https://twitter.com/intent/tweet?text=Highlights%20of%20EMNLP%202016%3A%20Dialogue%2C%20deep%20learning%2C%20and%20more%20%C2%BB&amp;hashtags=natural%20language%20processing,deep%20learning,machine%20learning,word%20embeddings&amp;url=http://ruder.io/emnlp-2016-highlights/">
        <img id="post-image" src="../content/images/2016/11/emnlp_cover_image.jpg" alt="Highlights of EMNLP 2016: Dialogue, deep learning, and more">
        <h1 class="icon-reverse icon-social-twitter-post" id="post-title">Highlights of EMNLP 2016: Dialogue, deep learning, and more</h1>
      </a>
    </header>

    <div id="post-content" class="post tag-natural-language-processing tag-deep-learning tag-machine-learning tag-word-embeddings">
      <p><em>This post originally appeared on the <a href="http://blog.aylien.com/highlights-emnlp-2016-dialogue-deeplearning-and-more/">AYLIEN blog</a>.</em></p>

<p>I spent the past week in Austin, Texas at <a href="http://www.emnlp2016.net/">EMNLP 2016</a>, the Conference on Empirical Methods in Natural Language Processing.</p>

<p>There were a lot of papers at the conference (179 long papers, 87 short papers, and 9 TACL papers all in all) -- too many to read each single one. The entire program can be found <a href="http://www.emnlp2016.net/proceedings/2016-emnlp-handbook.pdf">here</a>. In the following, I will highlight some trends and papers that caught my eye:</p>

<p><strong>Reinforcement learning</strong>: One thing that stood out was that RL seems to be slowly finding its footing in NLP, with more and more people using it to solve complex problems:</p>

<ul>
<li><a href="http://127.0.0.1:2368/emnlp-2016-highlights/(https://arxiv.org/pdf/1608.05604.pdf">Hahn and Keller</a> model human reading;</li>
<li><a href="https://arxiv.org/pdf/1609.07317.pdf">Miao and Blunsom</a> summarise sentences;</li>
<li><a href="https://arxiv.org/pdf/1606.01541.pdf">Li et al.</a> generate dialogues;</li>
<li><a href="https://arxiv.org/pdf/1606.03667.pdf">He et al.</a> predict reddit threads;</li>
<li><a href="https://arxiv.org/pdf/1609.08667.pdf">Clark and Manning</a> perform coreference resolution;</li>
<li><a href="https://arxiv.org/pdf/1603.07954.pdf">Narasimhan et al.</a> query the web for additional evidence to improve information extraction in one of the two best papers.</li>
</ul>

<p><strong>Dialogue</strong>: Dialogue was a focus of the conference with all of the three keynote speakers dealing with different aspects of dialogue: Christopher Potts talked about pragmatics and how to reason about the intentions of the conversation partner; Stefanie Tellex concentrated on how to use dialogue for human-robot collaboration; finally, Andreas Stolcke focused on the problem of addressee detection in his talk. Among the papers, a few that dealt with dialogue stood out:</p>

<ul>
<li><a href="https://arxiv.org/pdf/1604.00562.pdf">Andreas and Klein</a> model pragmatics in dialogue with neural speakers and listeners;</li>
<li><a href="https://arxiv.org/pdf/1603.08023.pdf">Liu et al.</a> show how <em>not</em> to evaluate your dialogue system;</li>
<li><a href="http://www.aclweb.org/anthology/D/D16/D16-1231.pdf">Ouchi and Tsuboi</a> select addressees and responses in multi-party conversations;</li>
<li><a href="http://arxiv.org/abs/1606.03352">Wen et al.</a> study diverse architectures for dialogue modelling. </li>
</ul>

<p><strong>Sequence-to-sequence</strong>: Seq2seq models were again front and center. It is not common for a method to have its own session two years after its introduction <a href="http://arxiv.org/abs/1409.3215%5Cnhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks">(Sutskever et al., 2014)</a>. While in the past years, many papers employed seq2seq e.g. for Neural Machine Translation, some papers this year focused on improving the seq2seq framework:</p>

<ul>
<li><a href="https://arxiv.org/pdf/1606.02960.pdf">Wiseman and Rush</a> extend seq2seq to learn global sequence scores;</li>
<li><a href="https://arxiv.org/pdf/1609.08194">Yu et al.</a> perform online seq2seq learning;</li>
<li><a href="https://arxiv.org/pdf/1606.07947">Kim and Rush</a> extend Knowledge Distillation (<a href="https://arxiv.org/pdf/1503.02531.pdf">Hinton et al., 2015</a>) to seq2seq learning;</li>
<li><a href="https://arxiv.org/pdf/1609.09552.pdf">Kikuchi et al.</a> propose a method to control the output length in seq2seq models.</li>
</ul>

<p><strong>Semantic parsing</strong>: Since seq2seq's use for dialogue modelling was popularised by <a href="https://arxiv.org/pdf/1506.05869.pdf%20(http://arxiv.org/pdf/1506.05869.pdf)">Vinyals and Le</a>, it is harder to get it to work with goal-oriented tasks that require an intermediate representation on which to act. Semantic parsing is used to convert a message into a more meaningful representation that can be used by another component of the system. As this technique is useful for sophisticated dialogue systems, it is great to see progress in this area:</p>

<ul>
<li><a href="https://www.aclweb.org/anthology/D/D16/D16-1015.pdf">Yaruz et al.</a> infer answer types for semantic parsing;</li>
<li><a href="https://arxiv.org/pdf/1606.07046.pdf">Krishnamurthy et al.</a> parse to probabilistic programs;</li>
<li><a href="https://arxiv.org/pdf/1609.09315.pdf">Kocisky et al.</a> perform semantic parsing with semi-supervised sequential auto encoders.</li>
</ul>

<p><strong>X-to-text (or natural language generation)</strong>: While mapping from text-to-text with the seq2seq paradigm is still prevalent, EMNLP featured some cool papers on natural language generation from other inputs:</p>

<ul>
<li><a href="https://www.aclweb.org/anthology/D/D16/D16-1032.pdf">Kiddon et al.</a> map from a recipe name and ingredients to a recipe by ticking of items off a checklist;</li>
<li><a href="https://www.aclweb.org/anthology/D/D16/D16-1126.pdf">Ghazvininejad et al.</a> generate a poem based on a topic;</li>
<li><a href="https://arxiv.org/pdf/1606.03821.pdf">Monroe et al.</a> map from a color to its name;</li>
<li><a href="https://arxiv.org/pdf/1610.06210.pdf">Koncel-Kedziorski et al.</a> re-write the theme of an algebra problem (think: boring physics book to Star Wars);</li>
<li><a href="http://arxiv.org/abs/1603.07771">Lebret et al.</a> generate biographical sentences from Wikipedia fact tables.</li>
</ul>

<p><strong>Parsing</strong>: Parsing and syntax are a mainstay of every NLP conference and the community seems to particularly appreciate innovative models that push the state-of-the-art in parsing: The ACL '16 outstanding paper by <a href="https://arxiv.org/pdf/1603.06042.pdf">Andor et al.</a> introduced a globally normalized model for parsing, while the best EMNLP ‘16 paper by <a href="https://arxiv.org/pdf/1607.01432.pdf">Lee et al.</a> combines a global parsing model with a local search over subtrees.</p>

<p><strong>Word embeddings</strong>: There were still papers on word embeddings, but it felt less overwhelming than at the past EMNLP or ACL, with most methods trying to fix a particular flaw rather than training embeddings for embeddings' sake. <a href="https://arxiv.org/pdf/1608.01961.pdf">Pilevhar and Collier</a> de-conflate senses in word embeddings, while <a href="https://arxiv.org/pdf/1607.02789.pdf">Wieting et al.</a> achieve state-of-the-art results for character-based embeddings.</p>

<p><strong>Sentiment analysis</strong>: Sentiment analysis has been popular in recent years (as attested by the introductions of many recent papers on sentiment analysis). Sadly, many of the conference papers on sentiment analysis reduce to leveraging the latest deep neural network for the task to beat the previous state-of-the-art without providing additional insights. There are, however, some that break the mold: <a href="http://www.aclweb.org/anthology/D/D16/D16-1169.pdf">Teng et al.</a> find an effective way to incorporate sentiment lexicons into a neural network, while <a href="https://www.aclweb.org/anthology/D/D16/D16-1173.pdf">Hu et al.</a> incorporate structured knowledge into their sentiment analysis model.</p>

<p><strong>Deep Learning</strong>: By now, it is clear to everyone: Deep Learning is here to stay. In fact, <em>deep learning</em> and <em>neural networks</em> claimed the two top spots of keywords that were used to describe the submitted papers. The majority of papers used at least an LSTM; using no neural network seems almost contrarian now and is something that needs to be justified. However, there are still many things that need to be improved -- which leads us to...</p>

<p><strong>Uphill Battles</strong>: While making incremental progress is important to secure grants and publish papers, we should not lose track of the long-term goals. In this spirit, one of the best workshops that I've attended was the <em>Uphill Battles in Language Processing</em> workshop, which featured 12 talks and not one, but <em>four</em> all-star panels on text understanding, natural language generation, dialogue and speech, and grounded language. Summaries of the panel discussions should be available soon at the <a href="http://www.coli.uni-saarland.de/~mroth/UphillBattles/">workshop website</a>.</p>

<p>This was my brief review of some of the trends of EMNLP 2016. I hope it was helpful.</p>

<p>Cover image credit: <a href="https://www.flickr.com/photos/148956535@N07/">Jackie Cheung</a></p>
    </div>

    <div class="post related">
        <a rel="prev" id="prev-btn" class="btn small square" href="../secret-word2vec/">← On word embeddings - Part 3: The secret ingredients of word2vec</a>

        <a rel="next" id="next-btn" class="btn small square" href="../cross-lingual-embeddings/">A survey of cross-lingual embedding models →</a>
    </div>

    <footer class="post comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
  (function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + window.disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</footer>

  </article>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>  

        <footer>
  <span class="copyright">
    © 2018. All rights reserved. Built with <a href="https://ghost.org/" target="_blank">Ghost</a> and <a href="https://github.com/Kikobeats/uno-zen" target="_blank">Uno Zen</a> theme.
  </span>
</footer>
      </section>
    </main>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
<script>jQuery = Zepto</script>
    <script src="../assets/js/uno-zen.js?v=35ddfd5849" type="text/javascript" charset="utf-8"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>
  if (window.ga_id) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', window.ga_id, 'auto');
    ga('require', 'linkid', 'linkid.js');
    ga('send', 'pageview');
  }
</script>
  </body>
